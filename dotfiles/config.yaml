# Create log file and sbatch jobs per rule
cluster:
  mkdir -p logs/{rule}/ &&
  sbatch
    --cpus-per-task={threads}
    --mem={resources.mem_mb}
    --time={resources.time}
    --job-name=smk-{rule}
    --ntasks={resources.nodes}
    --nodes={resources.nodes}
    --output=logs/{rule}/{jobid}.{resources.attempt_cnt}.out
    --error=logs/{rule}/{jobid}.{resources.attempt_cnt}.err
    --partition={resources.partition}
    --parsable

# The default resources per rule (overright by defining a `resources:` section in a rule)
default-resources:
  - mem_mb=2000
  - time=240
  - partition=low2
  - nodes=1
  - attempt_cnt=attempt

# Snakemake cli options
cores: 64
jobs: 100
latency-wait: 60
restart-times: 5
max-jobs-per-second: 100
local-cores: 1
max-status-checks-per-second: 20
keep-going: True
rerun-incomplete: True
printshellcmds: True
scheduler: greedy
use-conda: True
conda-prefix: /home/<Change to your home directory>/miniconda3
conda-frontend: mamba
cluster-status: ~/.config/snakemake/slurm/slurm-status.py
shadow-prefix: /group/ctbrowngrp/scratch/<Change to your home directory>/snakemake-slurm
cluster-cancel: scancel
cluster-cancel-nargs: 1000
