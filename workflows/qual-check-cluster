# A snakemake workflow to check the quality of your sequence data and the sourmash signature generated!

import pandas as pd

configfile: "config/download-sketch-config.yaml"

metadata = pd.read_csv(config['metadata_file_path'], usecols=['Run', 'BioProject'])

DICT = metadata.to_dict(orient='index')

project_run ={each['BioProject']: {each['Run']} for each in DICT.values()}

for each in DICT.values():
    project = each['BioProject']
    run = each['Run']
    project_run[project] |= {run}

fastqc_input = [
    expand(
        f"qc/fastqc/{project}/{accession}_fastqc.html"
        )
    for project, sample_list in project_run.items() for accession in sample_list ]

projectlist=list({project for project, sample_list in project_run.items()})

PART_JOBS = {1: ['low2', 1], 2: ['low2', 1], 3: ['med2', 33], 4: ['med2', 33], 5: ['high2', 10000]}

rule all:
    input:
        fastqc_input,
        "qc/multiqc_report/multiqc_crc_report.html"

rule download_sra:
    output:
        temp("qc/sra/{project}/{accession}.sra")
    log:
        "logs/prefetch/{project}/{accession}.log"
    threads:
        10
    resources:
        mem_mb = lambda wildcards, attempt: 8 * 1024 * attempt,
        #time = lambda wildcards, attempt: 4 * 60 * attempt,
        #runtime = lambda wildcards, attempt: 4 * 60 * attempt,
        allowed_jobs=25,
        partition=lambda wildcards, attempt: PART_JOBS[attempt][0],
    conda:
        "envs/download-sketch-env.yaml"
    shell:
        """
        if [ ! -f "qc/fastqc/{wildcards.project}/{wildcards.accession}.html" ] && \
           [ ! -f "qc/sra/{wildcards.project}/{wildcards.accession}.sra" ]; then
            aws s3 cp --quiet --no-sign-request \
            s3://sra-pub-run-odp/sra/{wildcards.accession}/{wildcards.accession} \
            qc/sra/{wildcards.project}/{wildcards.accession}.sra \
            || prefetch {wildcards.accession} -o qc/sra/{wildcards.project}/{wildcards.accession}.sra
        fi
        """

rule dump_and_qc:
    input:
        sra_file="qc/sra/{project}/{accession}.sra"
    output:
        html="qc/fastqc/{project}/{accession}_fastqc.html",
        zip="qc/fastqc/{project}/{accession}_fastqc.zip",
    log:
        "logs/dump_and_qc.{project}.{accession}.log"
    threads: 32
    resources:
        mem_mb = lambda wildcards, attempt: 8 * 1024 * attempt,
        time = lambda wildcards, attempt: 1.5 * 60 * attempt,
        runtime = lambda wildcards, attempt: 1.5 * 60 * attempt,
        allowed_jobs=lambda wildcards, attempt: PART_JOBS[attempt][1],
        partition=lambda wildcards, attempt: PART_JOBS[attempt][0],
    conda:
        "envs/download-sketch-env.yaml"
    shell:
        """
        if [ ! -f "qc/fastqc/{wildcards.project}/{wildcards.accession}_fastqc" ] && \
           [ ! -f "qc/fastqc/{wildcards.project}/{wildcards.accession}.html" ] ; then

        # make a directory specific to user and job
        export MYTMP="/scratch/baumlerc/slurm_{jobid}"
        mkdir -p "$MYTMP"

        # force clean it up after job script ends
        function cleanup()(rm -rf "$MYTMP")
        trap cleanup EXIT

        # Get fastqc file
        fasterq-dump --stdout --concatenate-reads \
        --threads {threads} --bufsize 1000MB --curcache 10000MB --mem {resources.mem_mb} \
        {input.sra_file} -t "$MYTMP"| \
        fastqc stdin:{wildcards.accession} --outdir qc/fastqc/{wildcards.project}
        fi
        """

rule multiqc_report:
    input: [ expand(f"qc/fastqc/{project}/{accession}_fastqc.zip") for project, sample_list in project_run.items() for accession in sample_list ]
    output: "qc/multiqc_report/multiqc_crc_report.html"
    params:
        global_in = "qc/fastqc/*/*_fastqc.zip",
        global_out = "qc/multiqc_report/",
        projects = [f"{p}" for p in projectlist],
        local_in = [f"qc/fastqc/{p}" for p in projectlist],
        local_out = [f"qc/multiqc/{p}" for p in projectlist],
    conda: "envs/multiqc.yaml"
    threads: 1
    resources:
        time = lambda wildcards, attempt: 1.5 * 60 * attempt,
        runtime = lambda wildcards, attempt: 1.5 * 60 * attempt,
        mem_mb = lambda wildcards, attempt: 8 * 1024 * attempt,
    shell:"""
        # Create a multiqc report for ALL fastq files
        multiqc {params.global_in} --outdir {params.global_out} --filename "multiqc_complete_report.html" --interactive --force

        # A Bash script to create an individual project multiqc report
        projects="{params.projects}"
        IFS=' ' read -ra array <<< "$projects"
        for pro in "${{array[@]}}"; do
            multiqc qc/fastqc/$pro/*_fastqc.zip --outdir {params.global_out} --filename multiqc_${{pro}}_report.html --interactive --force
        done

#        cp qc/multiqc/multiqc_report.html ~/public_html/multiqc_report/multiqc_report.html
    """
