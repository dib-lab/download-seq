import pandas as pd

configfile: "config/download-sketch-config.yaml"

# Load the metadata file
metadata = pd.read_csv(config['metadata_file_path'], usecols=['Run'])

run_ids = metadata['Run'].tolist()

rule all:
    input:
        expand("sigs/{run_id}.sig", run_id=run_ids),

rule download_sra:
    output:
        "sra/{run_id}.sra"
    log:
        "logs/prefetch/{run_id}.log"
    conda:
        "env.yaml"
    shell:
        """
        if [ ! -f "sigs/{wildcards.run_id}.sig" ] && [ ! -f "sra/{wildcards.run_id}.sra" ]; then
            aws s3 cp --quiet --no-sign-request s3://sra-pub-run-odp/sra/{wildcards.run_id}/{wildcards.run_id} sra/{wildcards.run_id}.sra
        fi
        """

rule dump_and_sketch_sourmash_1k:
    threads: 8
    resources:
        mem_mb = lambda wildcards, attempt: 8 * 1024 * attempt,
        time = lambda wildcards, attempt: 4 * 60 * attempt,
        runtime = lambda wildcards, attempt: 4 * 60 * attempt,
        partition = "med2"
    input:
        sra_file = "sra/{run_id}.sra"
    output:
        "sigs/{run_id}.sig"
    log:
        "logs/sourmash/{run_id}.log"
    params:
        sra_dir = "sra/{run_id}"
    conda:
        "env.yaml"
    shell:
        """
        fasterq-dump --stdout --skip-technical \
        --fasta-unsorted --threads {threads} --min-read-len 100 --bufsize 1000MB --curcache 10000MB --mem {resources.mem_mb} \
        {input.sra_file} | \
        sourmash sketch dna -p k=31,scaled=1000,abund -p k=51,scaled=1000,abund - -o {output}
        rm -rf {input.sra_file}
        """
